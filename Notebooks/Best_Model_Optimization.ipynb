{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0c82bc",
   "metadata": {},
   "source": [
    "# Model Optimization & Hyperparameter Tuning\n",
    "\n",
    "## Purpose\n",
    "This notebook focuses on optimizing the best-performing sequence model from previous experiments (GRU) to further improve sentiment classification accuracy.  \n",
    "We will adjust key hyperparameters, experiment with deeper architectures, and evaluate the impact of these changes on validation accuracy.\n",
    "\n",
    "## Steps\n",
    "1. Load preprocessed IMDb dataset.\n",
    "2. Define a model-building function compatible with hyperparameter tuning.\n",
    "3. Use KerasTuner to search for optimal hyperparameters:\n",
    "   - Number of GRU units\n",
    "   - Number of layers\n",
    "   - Dropout rates\n",
    "   - Learning rate\n",
    "   - Batch size\n",
    "4. Train the best-found model and compare it with the previous version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71d7911d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_25080\\2424917221.py:9: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d80fc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "X_train = pd.read_csv(r\"F:\\Projects\\Sentiment Analysis\\data\\X_train.csv\")['clean_review']\n",
    "X_test = pd.read_csv(r\"F:\\Projects\\Sentiment Analysis\\data\\X_test.csv\")['clean_review']\n",
    "y_train = pd.read_csv(r\"F:\\Projects\\Sentiment Analysis\\data\\y_train.csv\").squeeze()\n",
    "y_test = pd.read_csv(r\"F:\\Projects\\Sentiment Analysis\\data\\y_test.csv\").squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e534181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "max_words = 10000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8ac2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model builder for KerasTuner\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "    \n",
    "    # Number of GRU units\n",
    "    gru_units = hp.Int('gru_units', min_value=32, max_value=128, step=32)\n",
    "    model.add(GRU(gru_units, return_sequences=False))\n",
    "    \n",
    "    # Dropout rate\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.6, step=0.1)\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Learning rate\n",
    "    lr = hp.Choice('learning_rate', values=[1e-4, 1e-3, 1e-2])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=lr),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5afb1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Projects\\Sentiment Analysis\\imdb-sentiment-rnn-env\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='gru_tuning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "042d3757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 08m 56s]\n",
      "val_accuracy: 0.7690833806991577\n",
      "\n",
      "Best val_accuracy So Far: 0.8845416903495789\n",
      "Total elapsed time: 00h 52m 41s\n"
     ]
    }
   ],
   "source": [
    "# Run tuner\n",
    "tuner.search(X_train_pad, y_train, epochs=5, validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30c1dac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 87ms/step - accuracy: 0.5030 - loss: 0.6939 - val_accuracy: 0.5197 - val_loss: 0.6905\n",
      "Epoch 2/5\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 87ms/step - accuracy: 0.5432 - loss: 0.6832 - val_accuracy: 0.8191 - val_loss: 0.4303\n",
      "Epoch 3/5\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 89ms/step - accuracy: 0.8670 - loss: 0.3313 - val_accuracy: 0.8849 - val_loss: 0.2976\n",
      "Epoch 4/5\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 87ms/step - accuracy: 0.9297 - loss: 0.1936 - val_accuracy: 0.8843 - val_loss: 0.3345\n",
      "Epoch 5/5\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 88ms/step - accuracy: 0.9612 - loss: 0.1237 - val_accuracy: 0.8787 - val_loss: 0.3918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20a8a037940>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best model\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "best_model = tuner.hypermodel.build(best_hp)\n",
    "best_model.fit(X_train_pad, y_train, epochs=5, validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37fda05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "best_model.save(r\"F:\\Projects\\Sentiment Analysis\\models\\gru_tuned_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4317eb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F:\\\\Projects\\\\Sentiment Analysis\\\\models\\\\tokenizer.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(tokenizer, r\"F:\\Projects\\Sentiment Analysis\\models\\tokenizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c002d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.8789 - loss: 0.3917\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "results = {\n",
    "    \"model\": \"GRU Tuned\",\n",
    "    \"best_hyperparameters\": {\n",
    "        \"gru_units\": best_hp.get('gru_units'),\n",
    "        \"dropout_rate\": best_hp.get('dropout_rate'),\n",
    "        \"learning_rate\": best_hp.get('learning_rate')\n",
    "    },\n",
    "    \"validation_accuracy\": float(best_model.evaluate(X_test_pad, y_test)[1])\n",
    "}\n",
    "\n",
    "with open(r\"F:\\Projects\\Sentiment Analysis\\models\\gru_tuned_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imdb-sentiment-rnn-env (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
